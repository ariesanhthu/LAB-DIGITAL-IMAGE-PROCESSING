{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13980406,"sourceType":"datasetVersion","datasetId":8911972},{"sourceId":672076,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":509159,"modelId":523825}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T06:35:36.224442Z","iopub.execute_input":"2025-12-04T06:35:36.224753Z","iopub.status.idle":"2025-12-04T06:35:38.101798Z","shell.execute_reply.started":"2025-12-04T06:35:36.224728Z","shell.execute_reply":"2025-12-04T06:35:38.101031Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DATA_ROOT = \"/kaggle/input/biped-edge-detection/BIPED/edges\"\nTRAIN_LIST = f\"{DATA_ROOT}/train_rgb.lst\"\n\nwith open(TRAIN_LIST) as f:\n    for _ in range(5):\n        print(repr(f.readline().strip()))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T06:35:38.103185Z","iopub.execute_input":"2025-12-04T06:35:38.103679Z","iopub.status.idle":"2025-12-04T06:35:38.117508Z","shell.execute_reply.started":"2025-12-04T06:35:38.103649Z","shell.execute_reply":"2025-12-04T06:35:38.116825Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Imports & Config","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nfrom typing import List, Tuple\n\nimport numpy as np\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchvision.transforms.functional as TF\n\n# Reproducibility\ndef set_seed(seed: int = 42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nset_seed(42)\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", DEVICE)\n\nDATA_ROOT = \"/kaggle/input/biped-edge-detection/BIPED/edges\"\nTRAIN_LIST = os.path.join(DATA_ROOT, \"train_rgb.lst\")\nTEST_LIST  = os.path.join(DATA_ROOT, \"test_rgb.lst\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T06:35:38.118230Z","iopub.execute_input":"2025-12-04T06:35:38.118404Z","iopub.status.idle":"2025-12-04T06:35:44.080056Z","shell.execute_reply.started":"2025-12-04T06:35:38.118389Z","shell.execute_reply":"2025-12-04T06:35:44.079301Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#  Dataset class for BIPED","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nfrom typing import Tuple, List\n\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms.functional as TF\n\nimport os\nimport random\nfrom typing import Tuple, List\n\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms.functional as TF\n\n\nclass BIPEDDataset(Dataset):\n    def __init__(\n        self,\n        root_dir: str,\n        list_file: str,\n        split: str = \"train\",          # \"train\" ho·∫∑c \"test\"\n        img_size: Tuple[int, int] = (320, 320),\n        is_train: bool = True,\n    ):\n        self.root_dir = root_dir      # \"/kaggle/input/biped-edge-detection/BIPED/edges\"\n        self.split = split            # \"train\" ho·∫∑c \"test\"\n        self.img_size = img_size\n        self.is_train = is_train\n\n        self.img_paths: List[str] = []\n        self.edge_paths: List[str] = []\n\n        with open(list_file, \"r\") as f:\n            for line in f:\n                line = line.strip()\n                if not line:\n                    continue\n\n                parts = line.split()\n                # file c≈© ki·ªÉu: rgbr/aug/p1/RGB_001.jpg rgbr/aug/p1/RGB_001.png\n                rgb_rel = parts[0]\n                edge_rel = parts[1] if len(parts) > 1 else parts[0]\n\n                # ‚ö†Ô∏è CH·ªà L·∫§Y T√äN FILE, B·ªé H·∫æT FOLDER C≈®\n                rgb_name = os.path.basename(rgb_rel)      # RGB_001.jpg\n                edge_name = os.path.basename(edge_rel)    # RGB_001.png\n\n                # ƒê·∫£m b·∫£o edge l√† .png\n                edge_stem, _ = os.path.splitext(edge_name)\n                edge_name = edge_stem + \".png\"\n\n                if self.split == \"train\":\n                    img_path  = os.path.join(\n                        self.root_dir, \"imgs\", \"train\", \"rgbr\", \"real\", rgb_name\n                    )\n                    edge_path = os.path.join(\n                        self.root_dir, \"edge_maps\", \"train\", \"rgbr\", \"real\", edge_name\n                    )\n                else:  # test\n                    img_path  = os.path.join(\n                        self.root_dir, \"imgs\", \"test\", \"rgbr\", rgb_name\n                    )\n                    edge_path = os.path.join(\n                        self.root_dir, \"edge_maps\", \"test\", \"rgbr\", edge_name\n                    )\n\n                self.img_paths.append(img_path)\n                self.edge_paths.append(edge_path)\n\n        print(\n            f\"[BIPEDDataset] Loaded {len(self.img_paths)} samples from \"\n            f\"{os.path.basename(list_file)} (split={self.split})\"\n        )\n\n    def __len__(self):\n        return len(self.img_paths)\n\n    def __getitem__(self, idx: int):\n        img_path  = self.img_paths[idx]\n        edge_path = self.edge_paths[idx]\n\n        # N·∫øu c√≤n l·ªói th√¨ b·∫≠t debug:\n        # print(\"IMG:\", img_path)\n        # print(\"EDGE:\", edge_path)\n\n        img = Image.open(img_path).convert(\"RGB\")\n        edge = Image.open(edge_path).convert(\"L\")\n\n        # Resize\n        img = img.resize(self.img_size, Image.BILINEAR)\n        edge = edge.resize(self.img_size, Image.NEAREST)\n\n        # Augment\n        if self.is_train:\n            if random.random() < 0.5:\n                img = TF.hflip(img)\n                edge = TF.hflip(edge)\n            if random.random() < 0.5:\n                img = TF.vflip(img)\n                edge = TF.vflip(edge)\n\n        img_tensor = TF.to_tensor(img)          # (3, H, W)\n        edge_tensor = TF.to_tensor(edge)        # (1, H, W)\n        edge_tensor = (edge_tensor > 0.5).float()\n\n        return img_tensor, edge_tensor\n\n\n\nIMG_SIZE   = (320, 320)\nBATCH_SIZE = 4\n\ntrain_dataset = BIPEDDataset(\n    root_dir=DATA_ROOT,\n    list_file=TRAIN_LIST,\n    split=\"train\",\n    img_size=IMG_SIZE,\n    is_train=True,\n)\n\ntest_dataset = BIPEDDataset(\n    root_dir=DATA_ROOT,\n    list_file=TEST_LIST,\n    split=\"test\",\n    img_size=IMG_SIZE,\n    is_train=False,\n)\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=0,     # ƒë·ªÉ debug cho d·ªÖ, OK r·ªìi h·∫µng tƒÉng\n    pin_memory=True,\n)\n\ntest_loader = DataLoader(   # d√πng test l√†m val\n    test_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=0,\n    pin_memory=True,\n)\n\nval_loader = test_loader\n\nx, y = next(iter(train_loader))\nprint(\"Batch shape:\", x.shape, y.shape)\n\nvx, vy = next(iter(val_loader))\nprint(\"Val batch:\", vx.shape, vy.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T06:35:44.082018Z","iopub.execute_input":"2025-12-04T06:35:44.082487Z","iopub.status.idle":"2025-12-04T06:35:45.041744Z","shell.execute_reply.started":"2025-12-04T06:35:44.082465Z","shell.execute_reply":"2025-12-04T06:35:45.040933Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# U-Net-like model for edge detection","metadata":{}},{"cell_type":"code","source":"class DoubleConv(nn.Module):\n    \"\"\"(Conv -> BN -> ReLU) * 2\"\"\"\n    def __init__(self, in_ch, out_ch):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n\nclass Down(nn.Module):\n    \"\"\"Downscaling with maxpool then double conv\"\"\"\n    def __init__(self, in_ch, out_ch):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.MaxPool2d(2),\n            DoubleConv(in_ch, out_ch),\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\n\nclass Up(nn.Module):\n    \"\"\"Upscaling then double conv (bilinear upsample)\"\"\"\n    def __init__(self, in_ch, out_ch):\n        super().__init__()\n        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n        self.conv = DoubleConv(in_ch, out_ch)\n\n    def forward(self, x1, x2):\n        x1 = self.up(x1)\n\n        # Pad if needed (in case of mismatched sizes)\n        diffY = x2.size()[2] - x1.size()[2]\n        diffX = x2.size()[3] - x1.size()[3]\n        x1 = F.pad(\n            x1,\n            [diffX // 2, diffX - diffX // 2,\n             diffY // 2, diffY - diffY // 2],\n        )\n\n        # Concatenate\n        x = torch.cat([x2, x1], dim=1)\n        return self.conv(x)\n\n\nclass EdgeUNet(nn.Module):\n    \"\"\"Small U-Net for edge detection (1-channel output).\"\"\"\n    def __init__(self, n_channels=3, n_classes=1):\n        super().__init__()\n        self.inc = DoubleConv(n_channels, 32)\n        self.down1 = Down(32, 64)\n        self.down2 = Down(64, 128)\n        self.down3 = Down(128, 256)\n\n        self.up1 = Up(256 + 128, 128)\n        self.up2 = Up(128 + 64, 64)\n        self.up3 = Up(64 + 32, 32)\n\n        self.outc = nn.Conv2d(32, n_classes, kernel_size=1)\n\n    def forward(self, x):\n        x1 = self.inc(x)       # 32\n        x2 = self.down1(x1)    # 64\n        x3 = self.down2(x2)    # 128\n        x4 = self.down3(x3)    # 256\n\n        x = self.up1(x4, x3)\n        x = self.up2(x,  x2)\n        x = self.up3(x,  x1)\n\n        logits = self.outc(x)  # (B, 1, H, W)\n        return logits\n\n\nmodel = EdgeUNet().to(DEVICE)\nprint(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T06:35:45.042839Z","iopub.execute_input":"2025-12-04T06:35:45.043107Z","iopub.status.idle":"2025-12-04T06:35:45.120313Z","shell.execute_reply.started":"2025-12-04T06:35:45.043088Z","shell.execute_reply":"2025-12-04T06:35:45.119490Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#  Loss, metrics & optimizer","metadata":{}},{"cell_type":"code","source":"# Hyperparameters\nLR = 1e-4\nEPOCHS = 5\nBATCH_SIZE = 4\nIMG_SIZE = (320, 320)\n\n# Loss function\ncriterion = nn.BCEWithLogitsLoss()\n\n# Optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\n\n\ndef compute_iou(pred: torch.Tensor, target: torch.Tensor, thresh: float = 0.5) -> float:\n    \"\"\"\n    pred, target: (B, 1, H, W), values in [0,1]\n    \"\"\"\n    pred_bin = (pred > thresh).float()\n    target_bin = (target > 0.5).float()\n\n    intersection = (pred_bin * target_bin).sum(dim=(1,2,3))\n    union = pred_bin.sum(dim=(1,2,3)) + target_bin.sum(dim=(1,2,3)) - intersection + 1e-6\n\n    iou = (intersection / union).mean().item()\n    return iou\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T06:35:45.121099Z","iopub.execute_input":"2025-12-04T06:35:45.121355Z","iopub.status.idle":"2025-12-04T06:35:45.127428Z","shell.execute_reply.started":"2025-12-04T06:35:45.121335Z","shell.execute_reply":"2025-12-04T06:35:45.126646Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training & Evaluation","metadata":{}},{"cell_type":"code","source":"def train_one_epoch(epoch, model, train_loader, optimizer, device, criterion):\n    model.train()\n    running_loss = 0.0\n    running_iou = 0.0\n\n    for step, (imgs, edges) in enumerate(train_loader):\n        imgs = imgs.to(device)\n        edges = edges.to(device)\n\n        optimizer.zero_grad()\n        logits = model(imgs)\n        loss = criterion(logits, edges)\n\n        loss.backward()\n        optimizer.step()\n\n        with torch.no_grad():\n            probs = torch.sigmoid(logits)\n            iou = compute_iou(probs, edges)\n\n        running_loss += loss.item()\n        running_iou += iou\n\n        if (step + 1) % 50 == 0:\n            print(\n                f\"Epoch [{epoch}] Step [{step+1}/{len(train_loader)}] \"\n                f\"Loss: {running_loss/(step+1):.4f}  IoU: {running_iou/(step+1):.4f}\"\n            )\n\n    epoch_loss = running_loss / len(train_loader)\n    epoch_iou = running_iou / len(train_loader)\n    print(f\"[Train] Epoch {epoch}: Loss={epoch_loss:.4f}, IoU={epoch_iou:.4f}\")\n    return epoch_loss, epoch_iou\n\n\ndef validate(epoch, model, val_loader, device, criterion):\n    model.eval()\n    val_loss = 0.0\n    val_iou = 0.0\n\n    with torch.no_grad():\n        for imgs, edges in val_loader:\n            imgs = imgs.to(device)\n            edges = edges.to(device)\n\n            logits = model(imgs)\n            loss = criterion(logits, edges)\n\n            probs = torch.sigmoid(logits)\n            iou = compute_iou(probs, edges)\n\n            val_loss += loss.item()\n            val_iou += iou\n\n    val_loss /= len(val_loader)\n    val_iou  /= len(val_loader)\n    print(f\"[Val]   Epoch {epoch}: Loss={val_loss:.4f}, IoU={val_iou:.4f}\")\n    return val_loss, val_iou\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T06:36:06.106498Z","iopub.execute_input":"2025-12-04T06:36:06.106842Z","iopub.status.idle":"2025-12-04T06:36:06.114689Z","shell.execute_reply.started":"2025-12-04T06:36:06.106819Z","shell.execute_reply":"2025-12-04T06:36:06.113558Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport matplotlib.pyplot as plt\n\nBEST_CKPT_PATH = \"/kaggle/working/biped_edge_unet_best.pth\"\nNUM_EPOCHS = 5\n\ndef run_training(model, train_loader, val_loader, optimizer, device, num_epochs = NUM_EPOCHS, save_path=BEST_CKPT_PATH):\n    best_val_iou = 0.0\n    best_epoch = 0\n\n    for epoch in range(1, num_epochs + 1):\n        train_one_epoch(epoch, model, train_loader, optimizer, device, criterion)\n        val_loss, val_iou = validate(epoch, model, val_loader, device, criterion)\n\n        if val_iou > best_val_iou:\n            best_val_iou = val_iou\n            best_epoch = epoch\n            torch.save({\n                \"epoch\": epoch,\n                \"model\": model.state_dict(),\n                \"optimizer\": optimizer.state_dict(),\n                \"val_loss\": val_loss,\n                \"val_iou\": val_iou\n            }, save_path)\n\n    print(f\"Training finished. Best IoU={best_val_iou:.4f} (epoch {best_epoch})\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T06:36:08.549149Z","iopub.execute_input":"2025-12-04T06:36:08.549434Z","iopub.status.idle":"2025-12-04T06:36:08.559344Z","shell.execute_reply.started":"2025-12-04T06:36:08.549410Z","shell.execute_reply":"2025-12-04T06:36:08.558380Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# D√πng test_loader nh∆∞ val_loader\nrun_training(\n    model=model,\n    train_loader=train_loader,\n    val_loader=test_loader,\n    optimizer=optimizer,\n    device=DEVICE,\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T06:50:25.393741Z","iopub.execute_input":"2025-12-04T06:50:25.394528Z","iopub.status.idle":"2025-12-04T06:50:28.622053Z","shell.execute_reply.started":"2025-12-04T06:50:25.394500Z","shell.execute_reply":"2025-12-04T06:50:28.620814Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\n\ndef load_trained_model(\n    model,\n    device,\n    local_ckpt=\"/kaggle/working/biped_edge_unet_best.pth\",\n    filename_in_input=\"biped_edge_unet_best.pth\",\n):\n    \"\"\"\n    ∆Øu ti√™n:\n    1. Load checkpoint local ·ªü /kaggle/working (n·∫øu ƒë√£ train trong run n√†y)\n    2. N·∫øu kh√¥ng c√≥, ƒëi t√¨m file `filename_in_input` trong /kaggle/input (datasets + models)\n    3. N·∫øu v·∫´n kh√¥ng c√≥, d√πng model kh·ªüi t·∫°o\n    \"\"\"\n\n    # 1) Check local checkpoint trong /kaggle/working\n    if os.path.exists(local_ckpt):\n        print(f\"üîπ Loading LOCAL checkpoint: {local_ckpt}\")\n        ckpt_path = local_ckpt\n    else:\n        # 2) T√¨m trong /kaggle/input\n        print(\"üîç Kh√¥ng th·∫•y local checkpoint, ƒëang t√¨m trong /kaggle/input ...\")\n        ckpt_path = None\n        for root, dirs, files in os.walk(\"/kaggle/input\"):\n            if filename_in_input in files:\n                ckpt_path = os.path.join(root, filename_in_input)\n                break\n\n        if ckpt_path is None:\n            print(\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y checkpoint trong /kaggle/input ‚Äî d√πng model kh·ªüi t·∫°o.\")\n            model.to(device)\n            return model\n\n    # 3) Load checkpoint t·ª´ ckpt_path\n    print(f\"‚úÖ Loading checkpoint from: {ckpt_path}\")\n    ckpt = torch.load(ckpt_path, map_location=device)\n\n    # T·ª± ƒëo√°n key\n    if \"model_state_dict\" in ckpt:\n        state_dict = ckpt[\"model_state_dict\"]\n    elif \"model\" in ckpt:\n        state_dict = ckpt[\"model\"]\n    else:\n        raise KeyError(f\"Checkpoint kh√¥ng c√≥ key 'model_state_dict' ho·∫∑c 'model'. Keys: {ckpt.keys()}\")\n\n    model.load_state_dict(state_dict)\n    model.to(device)\n    model.eval()\n    print(f\"‚ú® Loaded model, epoch = {ckpt.get('epoch', 'N/A')}, val_iou = {ckpt.get('val_iou', 'N/A')}\")\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T07:26:50.737546Z","iopub.execute_input":"2025-12-04T07:26:50.738101Z","iopub.status.idle":"2025-12-04T07:26:50.744822Z","shell.execute_reply.started":"2025-12-04T07:26:50.738074Z","shell.execute_reply":"2025-12-04T07:26:50.744022Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def visualize_predictions(model,\n                          val_loader,\n                          device,\n                          num_samples: int = 3,\n                          ckpt_path: str = BEST_CKPT_PATH):\n\n    # Load model (local n·∫øu c√≥, kh√¥ng th√¨ t√¨m trong /kaggle/input)\n    model = load_trained_model(\n        model,\n        device,\n        local_ckpt=ckpt_path,\n        filename_in_input=\"biped_edge_unet_best.pth\",  # ƒë√∫ng t√™n file b·∫°n upload\n    )\n\n    model.eval()\n\n    imgs, edges = next(iter(val_loader))\n    imgs = imgs.to(device)\n    edges = edges.to(device)\n\n    with torch.no_grad():\n        logits = model(imgs)\n        probs = torch.sigmoid(logits)\n\n    num_samples = min(num_samples, imgs.size(0))\n\n    for i in range(num_samples):\n        img_np = imgs[i].cpu().permute(1, 2, 0).numpy()\n        gt_np = edges[i].cpu().squeeze(0).numpy()\n        pred_np = probs[i].cpu().squeeze(0).numpy()\n\n        plt.figure(figsize=(12, 4))\n        plt.subplot(1, 3, 1)\n        plt.title(\"Input\")\n        plt.imshow(img_np)\n        plt.axis(\"off\")\n\n        plt.subplot(1, 3, 2)\n        plt.title(\"GT edge\")\n        plt.imshow(gt_np, cmap=\"gray\")\n        plt.axis(\"off\")\n\n        plt.subplot(1, 3, 3)\n        plt.title(\"Predicted edge\")\n        plt.imshow(pred_np, cmap=\"gray\")\n        plt.axis(\"off\")\n\n        plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T07:26:52.595241Z","iopub.execute_input":"2025-12-04T07:26:52.596031Z","iopub.status.idle":"2025-12-04T07:26:52.602799Z","shell.execute_reply.started":"2025-12-04T07:26:52.596005Z","shell.execute_reply":"2025-12-04T07:26:52.601952Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nvisualize_predictions(\n    model=model,\n    val_loader=test_loader,\n    device=DEVICE\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T07:26:54.845970Z","iopub.execute_input":"2025-12-04T07:26:54.846682Z","iopub.status.idle":"2025-12-04T07:26:56.233803Z","shell.execute_reply.started":"2025-12-04T07:26:54.846624Z","shell.execute_reply":"2025-12-04T07:26:56.232502Z"}},"outputs":[],"execution_count":null}]}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7239106d-1cfc-4af8-8687-d774c53fb82e",
   "metadata": {},
   "source": [
    "# Lab 4: Pytorch - basic neural networks\n",
    "\n",
    "### Full Name: Nguyen Anh Thư\n",
    "### Student's ID: 23127266"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dca5c05",
   "metadata": {},
   "source": [
    "# PyTorch Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300dc0db",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Import required libraries: `torch`, `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6447d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if required to install dependencies for this lab\n",
    "\n",
    "\n",
    "#!pip -q install torch numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eefe7e4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:42:03.197061Z",
     "iopub.status.busy": "2025-12-16T17:42:03.196715Z",
     "iopub.status.idle": "2025-12-16T17:42:03.203165Z",
     "shell.execute_reply": "2025-12-16T17:42:03.201860Z",
     "shell.execute_reply.started": "2025-12-16T17:42:03.197034Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1+cpu\n",
      "NumPy version: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac60391",
   "metadata": {},
   "source": [
    "## Working with Tensors\n",
    "\n",
    "Perform conversions between NumPy arrays and PyTorch Tensors, demonstrating shared memory mechanism.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "448faf42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:42:03.208315Z",
     "iopub.status.busy": "2025-12-16T17:42:03.207934Z",
     "iopub.status.idle": "2025-12-16T17:42:03.228454Z",
     "shell.execute_reply": "2025-12-16T17:42:03.227676Z",
     "shell.execute_reply.started": "2025-12-16T17:42:03.208288Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy array:\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "\n",
      "PyTorch Tensor from NumPy:\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "After modifying NumPy array:\n",
      "NumPy array: [[999.   2.   3.]\n",
      " [  4.   5.   6.]]\n",
      "PyTorch Tensor (shared memory): tensor([[999.,   2.,   3.],\n",
      "        [  4.,   5.,   6.]])\n",
      "\n",
      "NumPy array from Tensor:\n",
      "[[999.   2.   3.]\n",
      " [  4.   5.   6.]]\n",
      "\n",
      "Addition result:\n",
      "[[1998.    4.    6.]\n",
      " [   8.   10.   12.]]\n"
     ]
    }
   ],
   "source": [
    "# Create NumPy array\n",
    "np_array = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32)\n",
    "print(\"NumPy array:\")\n",
    "print(np_array)\n",
    "\n",
    "# Convert NumPy → PyTorch Tensor\n",
    "tensor_from_np = torch.from_numpy(np_array)\n",
    "print(\"\\nPyTorch Tensor from NumPy:\")\n",
    "print(tensor_from_np)\n",
    "\n",
    "# Demonstrate shared memory: changing NumPy array will affect Tensor\n",
    "np_array[0, 0] = 999\n",
    "print(\"\\nAfter modifying NumPy array:\")\n",
    "print(\"NumPy array:\", np_array)\n",
    "print(\"PyTorch Tensor (shared memory):\", tensor_from_np)\n",
    "\n",
    "# Convert PyTorch Tensor → NumPy\n",
    "np_array_from_tensor = tensor_from_np.numpy()\n",
    "print(\"\\nNumPy array from Tensor:\")\n",
    "print(np_array_from_tensor)\n",
    "\n",
    "# Perform addition\n",
    "result = np_array + np_array_from_tensor\n",
    "print(\"\\nAddition result:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3e2139",
   "metadata": {},
   "source": [
    "## Define Activation Functions\n",
    "\n",
    "Class `ActivationFunction` contains activation functions and their derivatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fb4cf99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:42:03.230088Z",
     "iopub.status.busy": "2025-12-16T17:42:03.229783Z",
     "iopub.status.idle": "2025-12-16T17:42:03.246727Z",
     "shell.execute_reply": "2025-12-16T17:42:03.245764Z",
     "shell.execute_reply.started": "2025-12-16T17:42:03.230056Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ActivationFunction:\n",
    "    \"\"\"Utility class for activation functions and their derivatives.\n",
    "    \n",
    "    This class provides static methods for sigmoid activation function\n",
    "    and its derivative, using PyTorch operations only.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(s):\n",
    "        \"\"\"Compute sigmoid activation function.\n",
    "        \n",
    "        Args:\n",
    "            s: Input tensor\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: Sigmoid activation of input, output range [0, 1]\n",
    "        \"\"\"\n",
    "        return 1 / (1 + torch.exp(-s))\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid_derivative(s):\n",
    "        \"\"\"Compute derivative of sigmoid function.\n",
    "        \n",
    "        Args:\n",
    "            s: Input tensor (typically sigmoid output)\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: Derivative of sigmoid at input point\n",
    "        \"\"\"\n",
    "        return s * (1 - s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf1b0056",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:42:03.248818Z",
     "iopub.status.busy": "2025-12-16T17:42:03.248455Z",
     "iopub.status.idle": "2025-12-16T17:42:03.276795Z",
     "shell.execute_reply": "2025-12-16T17:42:03.275616Z",
     "shell.execute_reply.started": "2025-12-16T17:42:03.248783Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([ 0.,  1., -1.])\n",
      "Sigmoid: tensor([0.5000, 0.7311, 0.2689])\n",
      "Sigmoid derivative: tensor([0.2500, 0.1966, 0.1966])\n"
     ]
    }
   ],
   "source": [
    "# Test activation functions\n",
    "test_input = torch.tensor([0.0, 1.0, -1.0], dtype=torch.float32)\n",
    "print(\"Input:\", test_input)\n",
    "print(\"Sigmoid:\", ActivationFunction.sigmoid(test_input))\n",
    "print(\"Sigmoid derivative:\", ActivationFunction.sigmoid_derivative(ActivationFunction.sigmoid(test_input)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1517179c",
   "metadata": {},
   "source": [
    "## Define Feed Forward Neural Network\n",
    "\n",
    "Class `FFNeuralNetwork` inherits from `nn.Module`, containing:\n",
    "- Initialization with weights and intermediate variables\n",
    "- Forward propagation\n",
    "- Backward propagation  \n",
    "- Training function\n",
    "- Save/Load weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ac48241",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:42:03.277864Z",
     "iopub.status.busy": "2025-12-16T17:42:03.277578Z",
     "iopub.status.idle": "2025-12-16T17:42:03.298604Z",
     "shell.execute_reply": "2025-12-16T17:42:03.297636Z",
     "shell.execute_reply.started": "2025-12-16T17:42:03.277841Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FFNeuralNetwork(nn.Module):\n",
    "    \"\"\"Feed Forward Neural Network implementation from scratch.\n",
    "    \n",
    "    A simple 3-layer neural network (input -> hidden -> output) with\n",
    "    sigmoid activation function and manual backpropagation implementation.\n",
    "    \n",
    "    Attributes:\n",
    "        inputSize: Number of input features (default: 3)\n",
    "        hiddenSize: Number of neurons in hidden layer (default: 4)\n",
    "        outputSize: Number of output neurons (default: 1)\n",
    "        W1: Weight matrix from input to hidden layer (inputSize x hiddenSize)\n",
    "        W2: Weight matrix from hidden to output layer (hiddenSize x outputSize)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=3, hidden_size=4, output_size=1):\n",
    "        \"\"\"Initialize the neural network.\n",
    "        \n",
    "        Args:\n",
    "            input_size: Number of input features\n",
    "            hidden_size: Number of neurons in hidden layer\n",
    "            output_size: Number of output neurons\n",
    "        \"\"\"\n",
    "        super(FFNeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.inputSize = input_size\n",
    "        self.hiddenSize = hidden_size\n",
    "        self.outputSize = output_size\n",
    "        \n",
    "        # Initialize weights with random values from normal distribution\n",
    "        self.W1 = nn.Parameter(torch.randn(self.inputSize, self.hiddenSize))\n",
    "        self.W2 = nn.Parameter(torch.randn(self.hiddenSize, self.outputSize))\n",
    "        \n",
    "        # Intermediate variables for forward pass\n",
    "        self.z = None  # Input to hidden layer (before activation)\n",
    "        self.z2 = None  # Hidden layer output (after activation)\n",
    "        self.z3 = None  # Input to output layer (before activation)\n",
    "        \n",
    "        # Intermediate variables for backward pass\n",
    "        self.z_activation = None\n",
    "        self.z_activation_derivative = None\n",
    "        self.out_error = None\n",
    "        self.out_delta = None\n",
    "        self.z2_error = None\n",
    "        self.z2_delta = None\n",
    "    \n",
    "    def activation(self, z):\n",
    "        \"\"\"Apply sigmoid activation function.\n",
    "        \n",
    "        Args:\n",
    "            z: Input tensor\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: Activated output\n",
    "        \"\"\"\n",
    "        self.z_activation = ActivationFunction.sigmoid(z)\n",
    "        return self.z_activation\n",
    "    \n",
    "    def activation_derivative(self, z):\n",
    "        \"\"\"Compute derivative of sigmoid activation.\n",
    "        \n",
    "        Args:\n",
    "            z: Input tensor (typically activated output)\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: Derivative of activation\n",
    "        \"\"\"\n",
    "        self.z_activation_derivative = ActivationFunction.sigmoid_derivative(z)\n",
    "        return self.z_activation_derivative\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"Perform forward propagation through the network.\n",
    "        \n",
    "        Args:\n",
    "            X: Input tensor of shape (batch_size, inputSize)\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: Output of the network, shape (batch_size, outputSize)\n",
    "        \"\"\"\n",
    "        # Layer 1: Input to Hidden\n",
    "        self.z = torch.matmul(X, self.W1)  # z = X @ W1\n",
    "        self.z2 = self.activation(self.z)  # z2 = sigmoid(z)\n",
    "        \n",
    "        # Layer 2: Hidden to Output\n",
    "        self.z3 = torch.matmul(self.z2, self.W2)  # z3 = z2 @ W2\n",
    "        output = self.activation(self.z3)  # output = sigmoid(z3)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def backward(self, X, y, output, learning_rate):\n",
    "        \"\"\"Perform backward propagation and update weights.\n",
    "        \n",
    "        Args:\n",
    "            X: Input tensor of shape (batch_size, inputSize)\n",
    "            y: Target tensor of shape (batch_size, outputSize)\n",
    "            output: Predicted output from forward pass\n",
    "            learning_rate: Learning rate for weight updates\n",
    "        \"\"\"\n",
    "        # Output layer error and delta\n",
    "        self.out_error = y - output  # Error at output\n",
    "        self.out_delta = self.out_error * self.activation_derivative(output)\n",
    "        \n",
    "        # Hidden layer error and delta\n",
    "        self.z2_error = torch.matmul(self.out_delta, torch.t(self.W2))\n",
    "        self.z2_delta = self.z2_error * self.activation_derivative(self.z2)\n",
    "        \n",
    "        # Update weights\n",
    "        with torch.no_grad():\n",
    "            self.W1 += torch.matmul(torch.t(X), self.z2_delta) * learning_rate\n",
    "            self.W2 += torch.matmul(torch.t(self.z2), self.out_delta) * learning_rate\n",
    "    \n",
    "    def train(self, X, y, learning_rate):\n",
    "        \"\"\"Train the network for one epoch.\n",
    "        \n",
    "        Args:\n",
    "            X: Input tensor of shape (batch_size, inputSize)\n",
    "            y: Target tensor of shape (batch_size, outputSize)\n",
    "            learning_rate: Learning rate for weight updates\n",
    "        \"\"\"\n",
    "        # Forward pass\n",
    "        output = self.forward(X)\n",
    "        \n",
    "        # Backward pass\n",
    "        self.backward(X, y, output, learning_rate)\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_weights(model, path):\n",
    "        \"\"\"Save model state_dict to file.\n",
    "        \n",
    "        This method saves only the weights (state_dict) instead of the entire\n",
    "        model object, which is more secure and avoids pickle-related issues.\n",
    "        \n",
    "        Args:\n",
    "            model: FFNeuralNetwork instance to save\n",
    "            path: File path to save the state_dict\n",
    "        \"\"\"\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print(f\"Model state_dict saved to {path}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_weights(path, input_size=3, hidden_size=4, output_size=1):\n",
    "        \"\"\"Load model weights from file.\n",
    "        \n",
    "        This method creates a new model instance and loads the saved state_dict.\n",
    "        This approach avoids pickle security issues and is compatible with\n",
    "        PyTorch 2.6+ default security settings.\n",
    "        \n",
    "        Args:\n",
    "            path: File path to load the state_dict from\n",
    "            input_size: Number of input features (must match saved model)\n",
    "            hidden_size: Number of neurons in hidden layer (must match saved model)\n",
    "            output_size: Number of output neurons (must match saved model)\n",
    "            \n",
    "        Returns:\n",
    "            FFNeuralNetwork: Model instance with loaded weights\n",
    "        \"\"\"\n",
    "        # Create a new model instance with the same architecture\n",
    "        model = FFNeuralNetwork(input_size=input_size, \n",
    "                               hidden_size=hidden_size, \n",
    "                               output_size=output_size)\n",
    "        \n",
    "        # Load the state_dict\n",
    "        state_dict = torch.load(path, weights_only=True)\n",
    "        model.load_state_dict(state_dict)\n",
    "        \n",
    "        print(f\"Model state_dict loaded from {path}\")\n",
    "        return model\n",
    "    \n",
    "    def predict(self, x_predict):\n",
    "        \"\"\"Make prediction on input data.\n",
    "        \n",
    "        Args:\n",
    "            x_predict: Input tensor for prediction\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: Predicted output\n",
    "        \"\"\"\n",
    "        print(\"Predict data based on trained weights:\")\n",
    "        print(\"Input:\\n\", x_predict)\n",
    "        output = self.forward(x_predict)\n",
    "        print(\"Output:\\n\", output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bbf089",
   "metadata": {},
   "source": [
    "## Prepare Sample Data\n",
    "\n",
    "Create and normalize training data (X, y) and test data (x_predict).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c4fd842",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:42:03.301059Z",
     "iopub.status.busy": "2025-12-16T17:42:03.300711Z",
     "iopub.status.idle": "2025-12-16T17:42:03.331165Z",
     "shell.execute_reply": "2025-12-16T17:42:03.329524Z",
     "shell.execute_reply.started": "2025-12-16T17:42:03.301028Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X:\n",
      "tensor([[2., 9., 0.],\n",
      "        [1., 5., 1.],\n",
      "        [3., 6., 2.]])\n",
      "\n",
      "Original y:\n",
      "tensor([[ 90.],\n",
      "        [100.],\n",
      "        [ 88.]])\n",
      "\n",
      "Normalized X (divided by column max):\n",
      "tensor([[0.6667, 1.0000, 0.0000],\n",
      "        [0.3333, 0.5556, 0.5000],\n",
      "        [1.0000, 0.6667, 1.0000]])\n",
      "\n",
      "Normalized y (divided by 100):\n",
      "tensor([[0.9000],\n",
      "        [1.0000],\n",
      "        [0.8800]])\n",
      "tensor([[0.6667, 1.0000, 0.0000],\n",
      "        [0.3333, 0.5556, 0.5000],\n",
      "        [1.0000, 0.6667, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "X = torch.tensor(([2, 9, 0], \n",
    "                  [1, 5, 1], \n",
    "                  [3, 6, 2]), dtype=torch.float)  # 3 x 3 tensor\n",
    "y = torch.tensor([[90], \n",
    "                  [100], \n",
    "                  [88]], dtype=torch.float)  # 3 x 1 tensor\n",
    "\n",
    "print(\"Original X:\")\n",
    "print(X)\n",
    "print(\"\\nOriginal y:\")\n",
    "print(y)\n",
    "\n",
    "# Normalize X by dividing each column by its max value\n",
    "X_max, _ = torch.max(X, 0)\n",
    "X = torch.div(X, X_max)\n",
    "print(\"\\nNormalized X (divided by column max):\")\n",
    "print(X)\n",
    "\n",
    "# Normalize y by dividing by 100 (max test score)\n",
    "y = y / 100\n",
    "print(\"\\nNormalized y (divided by 100):\")\n",
    "print(y)\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "670c2335-59ee-4cbe-84db-8b3ee601ec33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:42:03.332355Z",
     "iopub.status.busy": "2025-12-16T17:42:03.332096Z",
     "iopub.status.idle": "2025-12-16T17:42:03.351470Z",
     "shell.execute_reply": "2025-12-16T17:42:03.350456Z",
     "shell.execute_reply.started": "2025-12-16T17:42:03.332328Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original x_predict:\n",
      "tensor([[3., 8., 4.]])\n",
      "\n",
      "Normalized x_predict:\n",
      "tensor([[1.0000, 0.8889, 2.0000]])\n",
      "tensor([3., 9., 2.])\n"
     ]
    }
   ],
   "source": [
    "# Prediction data\n",
    "x_predict = torch.tensor([[3, 8, 4]], dtype=torch.float)  # 1 x 3 tensor\n",
    "\n",
    "print(\"Original x_predict:\")\n",
    "print(x_predict)\n",
    "\n",
    "# Normalize x_predict\n",
    "x_predict = torch.div(x_predict, X_max)\n",
    "print(\"\\nNormalized x_predict:\")\n",
    "print(x_predict)\n",
    "print(X_max)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63390aa",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Train the network for 1000 epochs, print loss after each epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4cc7d6fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:42:03.353512Z",
     "iopub.status.busy": "2025-12-16T17:42:03.352712Z",
     "iopub.status.idle": "2025-12-16T17:42:03.878908Z",
     "shell.execute_reply": "2025-12-16T17:42:03.877985Z",
     "shell.execute_reply.started": "2025-12-16T17:42:03.353479Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Number of epochs: 1000\n",
      "Learning rate: 0.1\n",
      "\n",
      "Epoch #1 - Loss: 0.349490\n",
      "Epoch #100 - Loss: 0.022979\n",
      "Epoch #200 - Loss: 0.009164\n",
      "Epoch #300 - Loss: 0.006303\n",
      "Epoch #400 - Loss: 0.005276\n",
      "Epoch #500 - Loss: 0.004801\n",
      "Epoch #600 - Loss: 0.004545\n",
      "Epoch #700 - Loss: 0.004392\n",
      "Epoch #800 - Loss: 0.004292\n",
      "Epoch #900 - Loss: 0.004221\n",
      "Epoch #1000 - Loss: 0.004168\n",
      "\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Create neural network instance\n",
    "model = FFNeuralNetwork(input_size=3, hidden_size=4, output_size=1)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.1\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(f\"Number of epochs: {num_epochs}\")\n",
    "print(f\"Learning rate: {learning_rate}\\n\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass to compute loss\n",
    "    output = model(X)\n",
    "    loss = torch.mean((y - output) ** 2).detach().item()\n",
    "    \n",
    "    # Print loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0 or epoch == 0:\n",
    "        print(f\"Epoch #{epoch + 1} - Loss: {loss:.6f}\")\n",
    "    \n",
    "    # Training step\n",
    "    model.train(X, y, learning_rate)\n",
    "\n",
    "print(\"\\nTraining completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226da0e0",
   "metadata": {},
   "source": [
    "## Save Model\n",
    "\n",
    "Save the trained model's state_dict (weights only) to file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bffe2060-13bb-4c4e-8fd8-a83b040f39c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:42:03.928943Z",
     "iopub.status.busy": "2025-12-16T17:42:03.928679Z",
     "iopub.status.idle": "2025-12-16T17:42:03.946114Z",
     "shell.execute_reply": "2025-12-16T17:42:03.944817Z",
     "shell.execute_reply.started": "2025-12-16T17:42:03.928921Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['W1', 'W2'])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "144b6568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:42:03.947070Z",
     "iopub.status.busy": "2025-12-16T17:42:03.946797Z",
     "iopub.status.idle": "2025-12-16T17:42:03.966413Z",
     "shell.execute_reply": "2025-12-16T17:42:03.965416Z",
     "shell.execute_reply.started": "2025-12-16T17:42:03.947036Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state_dict saved to ffnn_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Save trained model\n",
    "model_path = \"ffnn_model.pth\"\n",
    "FFNeuralNetwork.save_weights(model, model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7139e974",
   "metadata": {},
   "source": [
    "## Loading model and Prediction\n",
    "\n",
    "Load saved state_dict by creating a new model instance with matching architecture, then load the weights. Perform prediction on new data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c2dd792",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:42:03.987995Z",
     "iopub.status.busy": "2025-12-16T17:42:03.987752Z",
     "iopub.status.idle": "2025-12-16T17:42:04.018195Z",
     "shell.execute_reply": "2025-12-16T17:42:04.017285Z",
     "shell.execute_reply.started": "2025-12-16T17:42:03.987973Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state_dict loaded from ffnn_model.pth\n",
      "Predict data based on trained weights:\n",
      "Input:\n",
      " tensor([[1.0000, 0.8889, 2.0000]])\n",
      "Output:\n",
      " tensor([[0.8615]], grad_fn=<MulBackward0>)\n",
      "\n",
      "Predicted value (scaled): 0.861518\n",
      "Predicted value (original scale): 86.15\n"
     ]
    }
   ],
   "source": [
    "# Load saved model\n",
    "# Note: Must specify architecture parameters matching the saved model\n",
    "loaded_model = FFNeuralNetwork.load_weights(model_path, \n",
    "                                            input_size=3, \n",
    "                                            hidden_size=4, \n",
    "                                            output_size=1)\n",
    "\n",
    "# Make prediction\n",
    "prediction = loaded_model.predict(x_predict)\n",
    "print(f\"\\nPredicted value (scaled): {prediction.item():.6f}\")\n",
    "print(f\"Predicted value (original scale): {prediction.item() * 100:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db12b1b",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "Experiment with different hyperparameters to observe changes in loss and output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38484102",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:42:04.019446Z",
     "iopub.status.busy": "2025-12-16T17:42:04.019199Z",
     "iopub.status.idle": "2025-12-16T17:42:04.624094Z",
     "shell.execute_reply": "2025-12-16T17:42:04.622937Z",
     "shell.execute_reply.started": "2025-12-16T17:42:04.019424Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Experiment 1: Testing different learning rates\n",
      "============================================================\n",
      "Learning rate: 0.01 - Final Loss: 0.018902\n",
      "Learning rate: 0.10 - Final Loss: 0.002288\n",
      "Learning rate: 0.50 - Final Loss: 0.001411\n",
      "Learning rate: 1.00 - Final Loss: 0.002435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Experiment 1: Different learning rates\n",
    "print(\"=\" * 60)\n",
    "print(\"Experiment 1: Testing different learning rates\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "learning_rates = [0.01, 0.1, 0.5, 1.0]\n",
    "for lr in learning_rates:\n",
    "    model_exp = FFNeuralNetwork(input_size=3, hidden_size=4, output_size=1)\n",
    "    \n",
    "    # Train for 500 epochs\n",
    "    for epoch in range(500):\n",
    "        model_exp.train(X, y, lr)\n",
    "    \n",
    "    output = model_exp(X)\n",
    "    loss = torch.mean((y - output) ** 2).detach().item()\n",
    "    print(f\"Learning rate: {lr:4.2f} - Final Loss: {loss:.6f}\")\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2087ce8-85e9-4001-9909-000febf12146",
   "metadata": {},
   "source": [
    "### Config Hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa1cc402",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T17:42:04.625484Z",
     "iopub.status.busy": "2025-12-16T17:42:04.625225Z",
     "iopub.status.idle": "2025-12-16T17:42:19.146269Z",
     "shell.execute_reply": "2025-12-16T17:42:19.144827Z",
     "shell.execute_reply.started": "2025-12-16T17:42:04.625463Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Experiment 2: Testing different hidden layer sizes\n",
      "============================================================\n",
      "Hidden size:  2 - Final Loss: 0.004237\n",
      "Hidden size:  4 - Final Loss: 0.002038\n",
      "Hidden size:  6 - Final Loss: 0.003651\n",
      "Hidden size:  8 - Final Loss: 0.002758\n",
      "Hidden size: 16 - Final Loss: 0.003654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Experiment 2: Different number of hidden neurons\n",
    "print(\"=\" * 60)\n",
    "print(\"Experiment 2: Testing different hidden layer sizes\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "hidden_sizes = [2, 4, 6, 8, 16]\n",
    "for hidden_size in hidden_sizes:\n",
    "    model_exp = FFNeuralNetwork(input_size=3, hidden_size=hidden_size, output_size=1)\n",
    "    \n",
    "    # Train for 1000 epochs\n",
    "    for epoch in range(1000):\n",
    "        model_exp.train(X, y, 0.1)\n",
    "    \n",
    "    output = model_exp(X)\n",
    "    loss = torch.mean((y - output) ** 2).detach().item()\n",
    "    print(f\"Hidden size: {hidden_size:2d} - Final Loss: {loss:.6f}\")\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1021fdd0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-16T17:42:19.164985Z",
     "iopub.status.idle": "2025-12-16T17:42:19.165282Z",
     "shell.execute_reply": "2025-12-16T17:42:19.165166Z",
     "shell.execute_reply.started": "2025-12-16T17:42:19.165152Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Experiment 3: Predictions with Different Model Configurations\n",
      "================================================================================\n",
      "\n",
      "Test Input (normalized): [1.0, 0.8888888955116272, 2.0]\n",
      "Test Input (original): [3.0, 8.0, 4.0]\n",
      "\n",
      "====================================================================================================\n",
      "SUMMARY COMPARISON TABLE\n",
      "====================================================================================================\n",
      "Hidden | LR    | Loss (MSE)   | Prediction   | Time (s)  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "4      | 0.10  | 0.002576     | 90.92        | 3.7827    \n",
      "4      | 0.50  | 0.000532     | 92.92        | 3.7331    \n",
      "4      | 1.00  | 0.000317     | 93.92        | 3.5541    \n",
      "8      | 0.10  | 0.003627     | 97.77        | 4.2277    \n",
      "8      | 0.50  | 0.000394     | 89.99        | 3.4562    \n",
      "8      | 1.00  | 0.000099     | 97.47        | 5.4964    \n",
      "16     | 0.10  | 0.000977     | 92.45        | 5.9478    \n",
      "16     | 0.50  | 0.000135     | 92.99        | 6.1445    \n",
      "16     | 1.00  | 0.000062     | 98.75        | 5.9753    \n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Experiment 3: Compare predictions with different configurations\n",
    "print(\"=\" * 80)\n",
    "print(\"Experiment 3: Predictions with Different Model Configurations\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nTest Input (normalized):\", x_predict.squeeze().tolist())\n",
    "print(\"Test Input (original):\", (x_predict * X_max).squeeze().tolist())\n",
    "\n",
    "configs = [\n",
    "    {\"hidden_size\": 4, \"lr\": 0.1},\n",
    "    {\"hidden_size\": 4, \"lr\": 0.5},\n",
    "    {\"hidden_size\": 4, \"lr\": 1},\n",
    "    {\"hidden_size\": 8, \"lr\": 0.1},\n",
    "    {\"hidden_size\": 8, \"lr\": 0.5},\n",
    "    {\"hidden_size\": 8, \"lr\": 1},\n",
    "    {\"hidden_size\": 16, \"lr\": 0.1},\n",
    "    {\"hidden_size\": 16, \"lr\": 0.5},\n",
    "    {\"hidden_size\": 16, \"lr\": 1},\n",
    "]\n",
    "\n",
    "import time\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, config in enumerate(configs, 1):\n",
    "    \n",
    "    model_exp = FFNeuralNetwork(\n",
    "        input_size=3, \n",
    "        hidden_size=config[\"hidden_size\"], \n",
    "        output_size=1\n",
    "    )\n",
    "    \n",
    "    # Measure training time\n",
    "    start_time = time.time()\n",
    "    for epoch in range(10000):\n",
    "        model_exp.train(X, y, config[\"lr\"])\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    # Compute loss on training data\n",
    "    output = model_exp(X)\n",
    "    loss = torch.mean((y - output) ** 2).detach().item()\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        prediction = model_exp.forward(x_predict)\n",
    "        pred_scaled = prediction.item()\n",
    "        pred_original = pred_scaled * 100\n",
    "    \n",
    "    results.append({\n",
    "        \"hidden_size\": config['hidden_size'],\n",
    "        \"lr\": config['lr'],\n",
    "        \"loss\": loss,\n",
    "        \"prediction_scaled\": pred_scaled,\n",
    "        \"prediction_original\": pred_original,\n",
    "        \"training_time\": training_time\n",
    "    })\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"SUMMARY COMPARISON TABLE\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"{'Hidden':<6} | {'LR':<5} | {'Loss (MSE)':<12} | {'Prediction':<12} | {'Time (s)':<10}\")\n",
    "print(\"-\" * 100)\n",
    "for r in results:\n",
    "    print(f\"{r['hidden_size']:<6} | {r['lr']:<5.2f} | {r['loss']:<12.6f} | {r['prediction_original']:<12.2f} | {r['training_time']:<10.4f}\")\n",
    "\n",
    "print(\"=\" * 100)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
